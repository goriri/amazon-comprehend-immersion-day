{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Entity Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Import libraries necessary for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Identify your account number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your account id is 348052051973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sts_client = boto3.client(\"sts\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "print(\"Your account id is {}\".format(account_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Create the bucket for the lab (should already exist from Lab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket name used is comprehend-labs348052051973-2\n",
      "Bucket Exists\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"comprehend-labs\" + account_id +  \"-2\"\n",
    "print (\"Bucket name used is \" + bucket_name)\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "if (s3.Bucket(bucket_name).creation_date is None):\n",
    "    s3_client.create_bucket(Bucket=bucket_name)\n",
    "    print (\"Created bucket \" + bucket_name)\n",
    "else:\n",
    "    print (\"Bucket Exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Download the training data [entity list, docs], and the test data, then upload to the s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-26 03:09:56--  http://d1fjxffqn7wkdo.cloudfront.net/aws-offerings.csv\n",
      "Resolving d1fjxffqn7wkdo.cloudfront.net (d1fjxffqn7wkdo.cloudfront.net)... 99.84.185.76, 99.84.185.169, 99.84.185.9, ...\n",
      "Connecting to d1fjxffqn7wkdo.cloudfront.net (d1fjxffqn7wkdo.cloudfront.net)|99.84.185.76|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17492 (17K) [text/csv]\n",
      "Saving to: ‘aws-offerings.csv’\n",
      "\n",
      "aws-offerings.csv   100%[===================>]  17.08K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2022-05-26 03:09:56 (29.5 MB/s) - ‘aws-offerings.csv’ saved [17492/17492]\n",
      "\n",
      "--2022-05-26 03:09:56--  http://d1fjxffqn7wkdo.cloudfront.net/aws-offerings-docs.txt\n",
      "Resolving d1fjxffqn7wkdo.cloudfront.net (d1fjxffqn7wkdo.cloudfront.net)... 99.84.185.49, 99.84.185.76, 99.84.185.169, ...\n",
      "Connecting to d1fjxffqn7wkdo.cloudfront.net (d1fjxffqn7wkdo.cloudfront.net)|99.84.185.49|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 262659 (257K) [text/plain]\n",
      "Saving to: ‘aws-offerings-docs.txt’\n",
      "\n",
      "aws-offerings-docs. 100%[===================>] 256.50K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2022-05-26 03:09:56 (14.4 MB/s) - ‘aws-offerings-docs.txt’ saved [262659/262659]\n",
      "\n",
      "--2022-05-26 03:09:57--  http://d1fjxffqn7wkdo.cloudfront.net/aws-offerings-test.txt\n",
      "Resolving d1fjxffqn7wkdo.cloudfront.net (d1fjxffqn7wkdo.cloudfront.net)... 99.84.185.9, 99.84.185.49, 99.84.185.76, ...\n",
      "Connecting to d1fjxffqn7wkdo.cloudfront.net (d1fjxffqn7wkdo.cloudfront.net)|99.84.185.9|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 762 [text/plain]\n",
      "Saving to: ‘aws-offerings-test.txt’\n",
      "\n",
      "aws-offerings-test. 100%[===================>]     762  --.-KB/s    in 0s      \n",
      "\n",
      "2022-05-26 03:09:57 (77.9 MB/s) - ‘aws-offerings-test.txt’ saved [762/762]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_entity_prefix = 'entity-training'\n",
    "host_name = 'http://d1fjxffqn7wkdo.cloudfront.net'\n",
    "!wget {host_name}/aws-offerings.csv\n",
    "response = s3_client.upload_file('./aws-offerings.csv', bucket_name, \"{}/aws-offerings.csv\".format(s3_entity_prefix))\n",
    "\n",
    "!wget {host_name}/aws-offerings-docs.txt\n",
    "response = s3_client.upload_file('./aws-offerings-docs.txt', bucket_name, \"{}/aws-offerings-docs.txt\".format(s3_entity_prefix))\n",
    "        \n",
    "!wget {host_name}/aws-offerings-test.txt\n",
    "response = s3_client.upload_file('./aws-offerings-test.txt', bucket_name, \"{}/aws-offerings-test.txt\".format(s3_entity_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Text\", \"Type\"\n",
      "\"ACM\", \"AWS_OFFERING\"\n",
      "\"ACM PCA\", \"AWS_OFFERING\"\n",
      "\"ACM Private CA\", \"AWS_OFFERING\"\n",
      "\"AD Connector\", \"AWS_OFFERING\"\n",
      "\"AMS\", \"AWS_OFFERING\"\n",
      "\"API Gateway\", \"AWS_OFFERING\"\n",
      "\"AWS\", \"AWS_OFFERING\"\n",
      "\"AWS Amplify\", \"AWS_OFFERING\"\n",
      "\"AWS App Mesh\", \"AWS_OFFERING\"\n",
      "\"AWS AppSync\", \"AWS_OFFERING\"\n",
      "\"AWS Application Auto Scaling\", \"AWS_OFFERING\"\n",
      "\"AWS Application Discovery Service\", \"AWS_OFFERING\"\n",
      "\"AWS Artifact\", \"AWS_OFFERING\"\n",
      "\"AWS Auto Scaling\", \"AWS_OFFERING\"\n",
      "\"AWS Backup\", \"AWS_OFFERING\"\n",
      "\"AWS Batch\", \"AWS_OFFERING\"\n",
      "\"AWS Billing and Cost Management\", \"AWS_OFFERING\"\n",
      "\"AWS Blockchain Templates\", \"AWS_OFFERING\"\n",
      "\"AWS CLI\", \"AWS_OFFERING\"\n"
     ]
    }
   ],
   "source": [
    "!head -20 aws-offerings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS X-Ray Supports Analytics\n",
      "Use Analytics in X-Ray and delve into traces to quickly pinpoint issues that may effect your application and its underlying services.\n",
      "Amazon Sumerian Service Update on 2019-04-26\n",
      "Service improvements for Amazon Sumerian.\n",
      "Release: Amazon GameLift on 2019-04-25\n",
      "Realtime Servers provides ready-to-go, customizable game servers for mobile multiplayer games.\n",
      "AWS Budgets now Supports Instance Family Filtering for Reservation Coverage Alerts\n",
      "Starting today, you can use AWS Budgets to create Reservation Coverage budgets to monitor your Amazon EC2 reservations for a given instance family, and receive alerts when your reservation coverage falls below the threshold you define.\n",
      "Amazon Sumerian Service Update on 2019-04-08\n",
      "Service improvements for Amazon Sumerian.\n",
      "AWS X-Ray Supports AWS App Mesh Integration\n",
      "Use X-Ray to trace communications through AWS App Mesh's service mesh as it networks across multiple types of computer infrastructure.\n",
      "AWS X-Ray Groups: Deep Dive Dev Blog\n",
      "Use groups in X-Ray to create filtered service maps and record metrics for requests to a microservice, from a specific user, or for a recurring error case.\n",
      "AWS Announces the Ability to Consolidate Your Daily Credit Memos and Tax Credit Note Documents\n",
      "Amazon Web Services (AWS) is pleased to announce that you now have the option to have refunds and credits consolidated into a single credit memo instead of receiving multiple credit memos on the same day.\n",
      "AWS Deep Learning Containers for MXNet\n",
      "The AWS Deep Learning Containers for MXNet include containers for Training and Inference for CPU and GPU, optimized for performance and scale on AWS.\n",
      "AWS Deep Learning Containers for TensorFlow\n",
      "The AWS Deep Learning Containers for TensorFlow include containers for Training and Inference for CPU and GPU, optimized for performance and scale on AWS.\n"
     ]
    }
   ],
   "source": [
    "!head -20 aws-offerings-docs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Keep these outputs for the manual steps you're about to do. You can copy the outputs to a text doc locally (e.g., your laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity List Location:  s3://comprehend-labs348052051973-2/entity-training/aws-offerings.csv\n",
      "Training Documents Location:  s3://comprehend-labs348052051973-2/entity-training/aws-offerings-docs.txt\n",
      "Test Documents Location:  s3://comprehend-labs348052051973-2/entity-training/aws-offerings-test.txt\n",
      "Bucket Path:  s3://comprehend-labs348052051973-2\n"
     ]
    }
   ],
   "source": [
    "print(\"Entity List Location:  s3://{}/{}/aws-offerings.csv\".format(bucket_name,s3_entity_prefix))\n",
    "print(\"Training Documents Location:  s3://{}/{}/aws-offerings-docs.txt\".format(bucket_name,s3_entity_prefix))\n",
    "print(\"Test Documents Location:  s3://{}/{}/aws-offerings-test.txt\".format(bucket_name,s3_entity_prefix))\n",
    "print(\"Bucket Path:  s3://{}\".format(bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's go back to the console and kick off the jobs manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For extra credit, here are the steps to continue doing this in code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Add IAM permissions to SageMaker\n",
    "For SageMaker to kick off trainig jobs, it needs the ability to pass a role to the Comprehend service.  \n",
    "In the IAM console, add the following policy to the role that the SageMaker notebook created."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"iam:PassRole\",\n",
    "            \"Resource\": \"*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"iam:PassedToService\": \"comprehend.amazonaws.com\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the ARN for the role we created in the first Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This name should match the name of the role that was created in the first lab.\n",
    "role_name_base = 'AmazonComprehendServiceRoleS3FullAccess-ComprehendLabs'\n",
    "prefix_random_numbers = '' #If you added random numbers to the end of the 'ComprehendLabs' prefix, put them here\n",
    "if not prefix_random_numbers:\n",
    "    role_name = \"{}{}\".format(role_name_base,prefix_random_numbers)\n",
    "else:\n",
    "    role_name = role_name_base\n",
    "iam_client = boto3.client(\"iam\")\n",
    "response = iam_client.get_role(\n",
    "    RoleName=role_name\n",
    ")\n",
    "comprehend_arn = response['Role']['Arn']\n",
    "print(\"The ARN for the role is {}\".format(comprehend_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_client = boto3.client(\"comprehend\")\n",
    "response = comprehend_client.create_entity_recognizer(\n",
    "    RecognizerName=\"Recognizer-Name-Goes-Here-{}\".format(datetime.now()).replace(' ','-').replace(':','-').replace('.','-'),\n",
    "    LanguageCode=\"en\",\n",
    "    DataAccessRoleArn=comprehend_arn,\n",
    "    InputDataConfig={\n",
    "        \"EntityTypes\": [\n",
    "            {\n",
    "                'Type': \"AWS_OFFERING\"\n",
    "            }\n",
    "        ],\n",
    "        'EntityList': {\n",
    "            'S3Uri': \"s3://{}/{}/aws-offerings.csv\".format(bucket_name,s3_entity_prefix)\n",
    "        },\n",
    "        'Documents': {\n",
    "            'S3Uri': \"s3://{}/{}/aws-offerings-docs.txt\".format(bucket_name,s3_entity_prefix)\n",
    "        },\n",
    "        \n",
    "    }\n",
    ")\n",
    "recognizer_arn = response[\"EntityRecognizerArn\"]\n",
    "print(\"The ARN for the entity recognizer is {}\".format(recognizer_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Check the status of the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.describe_entity_recognizer(\n",
    "    EntityRecognizerArn=recognizer_arn\n",
    ")\n",
    "#The possible statuses for the custom entity recognizer are: 'SUBMITTED'|'TRAINING'|'DELETING'|'STOP_REQUESTED'|'STOPPED'|'IN_ERROR'|'TRAINED'\n",
    "print(\"The status of the custom entity recognizer is {}\".format(response['EntityRecognizerProperties']['Status']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Lets look at how the training did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.describe_entity_recognizer(\n",
    "    EntityRecognizerArn=recognizer_arn\n",
    ")\n",
    "if response['EntityRecognizerProperties']['Status'] == 'TRAINED':\n",
    "    print(json.dumps(response['EntityRecognizerProperties']['RecognizerMetadata'], indent=2))\n",
    "else:\n",
    "    print (\"Training job has not completed yet.  Please wait to check training performance until it has.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Start a batch entity recognition job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.describe_entity_recognizer(\n",
    "    EntityRecognizerArn=recognizer_arn\n",
    ")\n",
    "if response['EntityRecognizerProperties']['Status'] == 'TRAINED':\n",
    "    response = comprehend_client.start_entities_detection_job(\n",
    "        JobName='AWS_OFFERING-001',\n",
    "        EntityRecognizerArn=recognizer_arn,\n",
    "        LanguageCode=\"en\",\n",
    "        DataAccessRoleArn=comprehend_arn,\n",
    "        InputDataConfig={\n",
    "            'S3Uri': \"s3://{}/{}/aws-offerings-test.txt\".format(bucket_name,s3_entity_prefix),\n",
    "            'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "        },\n",
    "        OutputDataConfig={\n",
    "            'S3Uri': \"s3://{}/{}/results/\".format(bucket_name,s3_entity_prefix)\n",
    "        }\n",
    "    )\n",
    "    job_id = response['JobId']\n",
    "else:\n",
    "    print (\"Training job has not completed yet.  Please wait to start batch entity recognitino job until it has.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Check the status of the bacth transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.describe_entities_detection_job(\n",
    "    JobId=job_id\n",
    ")\n",
    "print(\"The status of the batch entity detection job is {}\".format(response['EntitiesDetectionJobProperties']['JobStatus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  Download the output of the batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.describe_entities_detection_job(\n",
    "    JobId=job_id\n",
    ")\n",
    "if response['EntitiesDetectionJobProperties']['JobStatus'] == \"COMPLETED\":\n",
    "    output_s3_uri = response['EntitiesDetectionJobProperties']['OutputDataConfig']['S3Uri']\n",
    "    s3_key = output_s3_uri.replace(\"s3://{}/\".format(bucket_name),'')\n",
    "    s3.meta.client.download_file(bucket_name, s3_key, 'output.tar.gz')\n",
    "    !tar zxvf output.tar.gz\n",
    "else:\n",
    "    print(\"Batch transformation job not complete.  Please wait until this job is completed before attempting to view output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.  Let's review the test data and the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.describe_entities_detection_job(\n",
    "    JobId=job_id\n",
    ")\n",
    "if response['EntitiesDetectionJobProperties']['JobStatus'] == \"COMPLETED\":\n",
    "    !head -20 aws-offerings-test.txt\n",
    "else:\n",
    "    print(\"Batch transformation job not complete.  Please wait until this job is completed before attempting to view output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = comprehend_client.describe_entities_detection_job(\n",
    "    JobId=job_id\n",
    ")\n",
    "if response['EntitiesDetectionJobProperties']['JobStatus'] == \"COMPLETED\":\n",
    "    !cat output\n",
    "else:\n",
    "    print(\"Batch transformation job not complete.  Please wait until this job is completed before attempting to view output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
